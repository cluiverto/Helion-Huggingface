{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924215cbddf24360ab51c20c4e5c3172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/8.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikoo\\miniconda3\\envs\\primo\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mikoo\\.cache\\huggingface\\hub\\models--transformersbook--distilbert-base-uncased-finetuned-clinc. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeab8fe75c6140d59987586c4ccf9eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62aa2f59ece34214825289e6e9484427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9732e87958b44b29ab9cc4079061ad0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99dfd7c4bb4447fa23d3decf7727198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd29061f8bdc4976b95ec5ee674054ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikoo\\miniconda3\\envs\\primo\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bert_ckpt  = \"transformersbook/distilbert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'calculator', 'score': 0.39931392669677734}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how much 4 that\"\n",
    "\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark():\n",
    "    def __init__(self, pipeline,dataset, optim_type=\"BERT baseline\"):\n",
    "        self.pipeline = pipeline\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "\n",
    "    def compute_accuracy(self):\n",
    "        pass\n",
    "\n",
    "    def compute_size(self):\n",
    "        pass\n",
    "\n",
    "    def time_pipeline(self):\n",
    "        pass\n",
    "\n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type] = update(self.time_pipeline())\n",
    "        metrics[self.optim_type] = update(self.compute_accuracy())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebb81a29b654b9cb2058dc685f16b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/24.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b6a178ceee4a39b430bb7b60b4aa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/312k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727218eaef664d2c8dea26dae7c54f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62c3983235b467ca746caa666b9ec65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/136k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1452cfa705c45e4b739291ac281a8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2623e5f1d529497b9daabf129ecf909b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dacf86638c4298a0713b8c6f0bdca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "clinic = load_dataset(\"clinc_oos\", \"plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer ninety dollars between glacier checking and farmers accounts, please',\n",
       " 'intent': 133}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinic[\"test\"][47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'how would you say fly in italian', 'intent': 61}\n",
      "{'text': \"what's the spanish word for pasta\", 'intent': 61}\n",
      "{'text': 'how would they say butter in zambia', 'intent': 61}\n",
      "{'text': 'how do you say fast in spanish', 'intent': 61}\n",
      "{'text': \"what's the word for trees in norway\", 'intent': 61}\n",
      "{'text': 'how does one say wonderful in german', 'intent': 61}\n",
      "{'text': 'how do they say tacos in mexico', 'intent': 61}\n",
      "{'text': 'how would one say cruiser in china', 'intent': 61}\n",
      "{'text': \"what's the french word you use for potato\", 'intent': 61}\n",
      "{'text': 'what would the word for grass be in finland', 'intent': 61}\n",
      "{'text': 'how do you say please in french', 'intent': 61}\n",
      "{'text': 'how would i say nice to meet you if i were russian', 'intent': 61}\n",
      "{'text': 'what is the right way to say excuse me in spanish', 'intent': 61}\n",
      "{'text': \"how do i say i'm sorry in chinese\", 'intent': 61}\n",
      "{'text': 'how would i say thank you if i were mexican', 'intent': 61}\n",
      "{'text': 'how would i say what is your name if i were french', 'intent': 61}\n",
      "{'text': 'how would i say i must be going now if i were german', 'intent': 61}\n",
      "{'text': 'how do i say bathroom in italian', 'intent': 61}\n",
      "{'text': 'how might i say hello if i were scottish', 'intent': 61}\n",
      "{'text': 'i must know how to say thank you in german', 'intent': 61}\n",
      "{'text': 'how would i say i love you if i were german', 'intent': 61}\n",
      "{'text': 'how would i say how are you today if i were mexican', 'intent': 61}\n",
      "{'text': 'how would i say where is the bathroom if i were korean', 'intent': 61}\n",
      "{'text': 'how would i say i need directions if i were french', 'intent': 61}\n",
      "{'text': 'how would i say i am lost if i were japanese', 'intent': 61}\n",
      "{'text': 'english to spanish for dog', 'intent': 61}\n",
      "{'text': 'what is dog in spanish', 'intent': 61}\n",
      "{'text': 'how do you say dog in spanish', 'intent': 61}\n",
      "{'text': 'dog in spanish', 'intent': 61}\n",
      "{'text': \"what's the spanish word for dog\", 'intent': 61}\n",
      "{'text': 'can you please provide me with assistance in moving money from one account to another', 'intent': 133}\n",
      "{'text': 'i would like help moving money between accounts', 'intent': 133}\n",
      "{'text': 'can you assist me in moving money from one account to another', 'intent': 133}\n",
      "{'text': 'i would like help moving money from one account to another', 'intent': 133}\n",
      "{'text': 'i would like assistance moving money from one account to another', 'intent': 133}\n",
      "{'text': 'can i move some money around', 'intent': 133}\n",
      "{'text': 'can i make a transfer between my accounts', 'intent': 133}\n",
      "{'text': 'i need to make a transfer of my money', 'intent': 133}\n",
      "{'text': 'can i move some money between my two accounts', 'intent': 133}\n",
      "{'text': 'i would like to distribute some money between my accounts', 'intent': 133}\n",
      "{'text': 'i would like to transfer $100 from my checking to saving account', 'intent': 133}\n",
      "{'text': 'help me transfer $100 from my checking to saving account', 'intent': 133}\n",
      "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}\n",
      "{'text': 'can you please help me move $100 from my checking to saving account', 'intent': 133}\n",
      "{'text': 'please move $100 from my checking to saving account', 'intent': 133}\n",
      "{'text': 'transfer seventeen dollars from rbs to woodforest account, please', 'intent': 133}\n",
      "{'text': 'send twelve dollars between cabelas and bank of london accounts, please', 'intent': 133}\n"
     ]
    }
   ],
   "source": [
    "# Funkcja do zwracania 10 przykładów\n",
    "def get_examples(clinic_data, num_examples=47):\n",
    "    examples = []\n",
    "    for i, entry in enumerate(clinic_data[\"test\"]):\n",
    "        if i >= num_examples:  # Ogranicz do 10 przykładów\n",
    "            break\n",
    "        examples.append(entry)\n",
    "    return examples\n",
    "\n",
    "# Uzyskanie 10 przykładów\n",
    "przyklady = get_examples(clinic)\n",
    "\n",
    "# Wyświetlenie przykładów\n",
    "for przyklad in przyklady:\n",
    "    print(przyklad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'how do they say goodbye in hawaii', 'intent': 61}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = clinic[\"train\"][47]\n",
    "#intents = clinic[\"test\"].features[\"intent\"]\n",
    "\n",
    "\n",
    "#intents.int2str(sample[\"intent\"])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
